---
permalink: /
title: "Agata Foryciarz"
excerpt: Agata Foryciarz"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a PhD student at Stanford Computer Science, where I'm advised by Professors [Sherri Rose](http://drsherrirose.org/) and [Carlos Guestrin](https://guestrin.su.domains/). 
I'm a member of the [Health Policy Data Science Lab](http://healthpolicydatascience.org/), and a Technology & Racial Equity graduate fellow at the [Center for
Comparative Studies in Race and Ethnicity](https://ccsre.stanford.edu/).

My research on algorithmic fairness explores statistical properties of machine learning models
used in clinical settings, and their implications for health equity.

Academic Publications 
======

<a href="https://informatics.bmj.com/content/29/1/e100460.full">Evaluating algorithmic fairness in the presence of clinical guidelines: the case of atherosclerotic cardiovascular disease risk estimation</a>
<br>
<b>Agata Foryciarz</b>, Stephen R. Pfohl, Birju Patel, Nigam H. Shah
<br>
<i>BMJ Health & Care Informatics 29, e100460</i>
<br>
\[<a href="https://arxiv.org/abs/2202.01906">paper</a>\]
\[<a href="https://github.com/agataf/fairness_eval_ascvd">code</a>\]

<a href="https://arxiv.org/abs/2202.01906">Net benefit, calibration, threshold selection, and training objectives for algorithmic fairness in healthcare</a>
<br>
Stephen R. Pfohl, Yizhe Xu, <b>Agata Foryciarz</b>, Nikolaos Ignatiadis, Julian Genkins, Nigam H. Shah
<br>
<i>arXiv:2202.01906</i>
<br>
\[<a href="https://arxiv.org/abs/2202.01906">preprint</a>\]

<a href="https://www.nature.com/articles/s41598-022-07167-7">A comparison of approaches to improve worst-case predictive model performance over patient subpopulations</a>
<br>
Stephen R. Pfohl, Haoran Zhang, Yizhe Xu, **Agata Foryciarz**, Marzyeh Ghassemi, Nigam H. Shah.
<br>
<i>Scientific Reports 12 (1), 1-13, 2022</i>
<br>
\[<a href="https://www.nature.com/articles/s41598-022-07167-7">paper</a>\] \[<a href="https://github.com/som-shahlab/subpopulation_robustness">code</a>\]


<a href="https://www.sciencedirect.com/science/article/abs/pii/S1532046420302495">An Empirical Characterization of Fair Machine Learning For Clinical Risk Prediction</a>
<br>
Stephen R. Pfohl, **Agata Foryciarz**, Nigam H. Shah.
<br>
<i>Journal of Biomedical Informatics, 113:103621, 2021</i>
<br>
\[<a href="https://www.sciencedirect.com/science/article/abs/pii/S1532046420302495">paper</a>\] \[<a href="https://arxiv.org/abs/2007.10306">preprint</a>\] \[<a href="https://github.com/som-shahlab/fairness_benchmark">code</a>\]

Non-academic Publications 
======
<a href="https://blogs.scientificamerican.com/observations/if-were-not-careful-tech-could-hurt-the-fight-against-covid-19/">
If We’re Not Careful, Tech Could Hurt the Fight against COVID-19</a>
<br>
Ria Kalluri, Lauren Gillespie, **Agata Foryciarz**, Wren Elhai, Sanjana Srivastava, Argyri Panezi, Lisa Einstein.<br>
<i>Scientific American Blog, 2020.</i>
<br>


<a href="https://medium.com/@szymielewicz/black-boxed-politics-cebc0d5a54ad">Black-Boxed Politics: Opacity is a Choice in AI Systems.</a>
<br>
Agata Foryciarz, Daniel Leufer, Katarzyna Szymielewicz.<br>
<i>Medium and Internazionale (Italian translation)</i>
<br>
\[<a href="https://medium.com/@szymielewicz/black-boxed-politics-cebc0d5a54ad">English</a>\]
\[<a href="https://www.internazionale.it/sommario/1346">Italian</a>\]


<a href="https://panoptykon.org/sztuczna-inteligencja-non-fiction">Sztuczna Inteligencja Non-Fiction.</a>
<br>
Anna Obem, Katarzyna Szymielewicz. Współpraca merytoryczna: Agata Foryciarz<br>
<i>Fundacja Panoptykon, 2020.</i>
<br>
